============version1==============
决策树三个算法 ID3 C4.5 CART
参考：http://www.cnblogs.com/wsine/p/5180315.html 系列文章
几乎没改动
============version2==============
更改了ID3
把数据集换成了西瓜数据集，计算了测试的正确率
问题：七三随机分训练集和测试集
      但是由于数据量比较小
      每一次的效果差异很大
      没有可比性
两点更改方法：1、取一次训练集和测试集的结果，比较三个算法（缺点：数据量小，一次的结果没有保证）
              2、计算多次正确率取平均值（缺点：不知道科不科学）

============version3==============
1、把三个算法融合成一个.py文件
分解开chooseBestFeatureToSplit（）这个函数
2、把训练集和测试集随机分开保存为traindata和testdata文件
3、保存三个算法训练出的决策树的图片在img文件下
4、ID3准确率0.5，其余两个准确率0.75
但是由于数据集太小，结果仅供参考【并不能说明什么】

============version4==============
1、处理连续值：对连续属性进行离散化
C4.5采用的二分法，排序离散属性，取每两个的中点作为划分点的候选点，
计算以每个划分点划分数据集的信息增益，取最大的那个划分点将连续属性化为两类变成离散属性，
用该属性进行划分的信息增益就是刚刚计算的最大信息增益。
增加两个函数：
splitDataSet_for_dec(dataSet, axis, value, small)
DataSetPredo(filename,decreteindex)
预处理函数DataSetPredo，对数据集提前离散化，然后再进行学习
2、数据集更改为含有连续值的西瓜数据
3、divideaData分离出训练集和测试集
watermelon为原数据
names里是属性名
4、CART准确率0.5，其余两个准确率0.66
同样，由于数据集太小，结果仅供参考【并不能说明什么】





